{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from recommenders.datasets import movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:12<00:00, 385KB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>196_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>63_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>226_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>154_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>306_242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating       id\n",
       "0   196    242       3  196_242\n",
       "1    63    242       3   63_242\n",
       "2   226    242       5  226_242\n",
       "3   154    242       3  154_242\n",
       "4   306    242       5  306_242"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size='100k',\n",
    "    header=['user', 'movie', 'rating', 'Timestamp'],\n",
    "    title_col='title'\n",
    ")\n",
    "\n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.int32)\n",
    "data['id'] = data.apply(lambda x: str(x['user'])+\"_\"+str(x['movie']), axis=1)\n",
    "df_full = data.loc[:, ['user', 'movie', 'rating', 'id']]\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRModel(object):\n",
    "\n",
    "    def __init__(self, df, user_col, item_col, rating_col):\n",
    "        self.df_full = df\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.rating_col = rating_col\n",
    "        self.build_mappings(self.user_col, self.item_col)\n",
    "        self.add_id_cols()\n",
    "\n",
    "    def build_mappings(self, user_col, item_col):\n",
    "        unique_users = self.df_full[user_col].unique()\n",
    "        self.user2id_map = dict(zip(unique_users, np.arange(unique_users.shape[0], dtype=np.int32)))\n",
    "        self.id2user_map = dict(zip(np.arange(unique_users.shape[0], dtype=np.int32), unique_users))\n",
    "\n",
    "        unique_movies = self.df_full[item_col].unique()\n",
    "        self.item2id_map = dict(zip(unique_movies, np.arange(unique_movies.shape[0], dtype=np.int32)))\n",
    "        self.id2item_map = dict(zip(np.arange(unique_movies.shape[0], dtype=np.int32), unique_movies))\n",
    "\n",
    "    def add_id_cols(self):\n",
    "        self.df_full['user_id'] = self.df_full[self.user_col].apply(lambda u: self.user2id_map[u])\n",
    "        self.df_full['movie_id'] = self.df_full[self.item_col].apply(lambda m: self.item2id_map[m])\n",
    "\n",
    "    def get_triplets(self, df_train, threshold=3, take_nonexisting=False, item_limit=50):\n",
    "        df_triplest = pd.DataFrame(columns=['user_id', 'positive_m_id', 'negative_m_id'])\n",
    "        data = []\n",
    "        users_without_data = []\n",
    "\n",
    "        for user_id in tqdm(df_train.user_id.unique()):\n",
    "            positive_movies = df_train[(df_train.user_id == user_id) & (df_train[self.rating_col] > threshold)].movie_id.values\n",
    "            negative_movies = df_train[(df_train.user_id == user_id) & (df_train[self.rating_col] <= threshold)].movie_id.values\n",
    "            if take_nonexisting:\n",
    "                all_movies = df_train['movie'].unique()\n",
    "                nonext_movies = np.setdiff1d(all_movies, df_train.loc[df_train[self.user_col]==123][self.item_col].values)\n",
    "                negative_movies = np.concatenate((negative_movies, nonext_movies), axis=0)\n",
    "\n",
    "            if negative_movies.shape[0] == 0 or positive_movies.shape[0] == 0:\n",
    "                users_without_data.append(user_id)\n",
    "                continue\n",
    "            \n",
    "            np.random.shuffle(positive_movies)\n",
    "            positive_movies = positive_movies[:item_limit]\n",
    "\n",
    "            np.random.shuffle(negative_movies)\n",
    "            negative_movies = negative_movies[:item_limit]\n",
    "\n",
    "            for positive_movie in positive_movies:\n",
    "                for negative_movie in negative_movies:\n",
    "                    data.append({'user_id': user_id, 'positive_m_id': positive_movie, 'negative_m_id': negative_movie})\n",
    "\n",
    "        df_triplest = df_triplest.append(data, ignore_index=True)\n",
    "        return df_triplest\n",
    "\n",
    "    def bpr_predict(self, model: Model, user_id: int, item_ids: list, user_layer='user_embedding', item_layer='item_embedding'):\n",
    "        \"\"\"\n",
    "        Predict by multiplication user vector by item matrix\n",
    "        \n",
    "        :return: list of the scores\n",
    "        \"\"\"\n",
    "        user_vector = model.get_layer(user_layer).get_weights()[0][user_id]\n",
    "        item_matrix = model.get_layer(item_layer).get_weights()[0][item_ids]\n",
    "\n",
    "        scores = (np.dot(user_vector, item_matrix.T))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def ranking(self, model, user_id, item_ids):\n",
    "        item_scores = [bpr_predict(model, user_id, i) for i in item_ids]\n",
    "        res_df = pd.DataFrame({'item_id': item_ids, 'score': item_scores}).sort_values(by='score', ascending=False)\n",
    "        return res_df\n",
    "\n",
    "    @tf.function\n",
    "    def identity_loss(self, _, y_pred):\n",
    "        return tf.math.reduce_mean(y_pred)\n",
    "\n",
    "    @tf.function\n",
    "    def bpr_triplet_loss(self, X: dict):\n",
    "        \"\"\"\n",
    "        Calculate triplet loss - as higher the difference between positive interactions\n",
    "        and negative interactions as better\n",
    "\n",
    "        :param X: X contains the user input, positive item input, negative item input\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "        positive_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, positive_item_latent), axis=-1, keepdims=True)\n",
    "        negative_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, negative_item_latent), axis=-1, keepdims=True)\n",
    "\n",
    "        return tf.math.subtract(tf.constant(1.0), tf.sigmoid(tf.math.subtract(positive_interactions, negative_interactions)))\n",
    "\n",
    "    def out_shape(self, shapes):\n",
    "        return shapes[0]\n",
    "        \n",
    "\n",
    "    def build_model(self, num_users: int, num_items: int, latent_dim: int) -> Model:\n",
    "        \"\"\"\n",
    "        Build a model for Bayesian personalized ranking\n",
    "\n",
    "        :param num_users: a number of the unique users\n",
    "        :param num_items: a number of the unique movies\n",
    "        :param latent_dim: vector length for the latent representation\n",
    "        :return: Model\n",
    "        \"\"\"\n",
    "        user_input = Input((1,), name='user_input')\n",
    "\n",
    "        positive_item_input = Input((1,), name='positive_item_input')\n",
    "        negative_item_input = Input((1,), name='negative_item_input')\n",
    "        # One embedding layer is shared between positive and negative items\n",
    "        item_embedding_layer = Embedding(num_items, latent_dim, name='item_embedding', input_length=1)\n",
    "\n",
    "        positive_item_embedding = Flatten()(item_embedding_layer(positive_item_input))\n",
    "        negative_item_embedding = Flatten()(item_embedding_layer(negative_item_input))\n",
    "\n",
    "        user_embedding = Embedding(num_users, latent_dim, name='user_embedding', input_length=1)(user_input)\n",
    "        user_embedding = Flatten()(user_embedding)\n",
    "\n",
    "        triplet_loss = Lambda(self.bpr_triplet_loss, output_shape=self.out_shape)([positive_item_embedding,\n",
    "                                                                negative_item_embedding,\n",
    "                                                                user_embedding])\n",
    "\n",
    "        model = Model(inputs=[positive_item_input, negative_item_input, user_input], outputs=triplet_loss)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, latent_dim=350, batch_size=256, num_epochs=3, lr=0.002):\n",
    "        num_users = len(self.user2id_map)\n",
    "        num_items = len(self.item2id_map)\n",
    "        model = self.build_model(num_users, num_items, latent_dim)\n",
    "        model.compile(loss=self.identity_loss, optimizer=Adam(learning_rate=lr))\n",
    "\n",
    "        # parameter space logging\n",
    "        trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "        non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "        print('Total number of parameters: {:,}'.format(trainable_count + non_trainable_count))\n",
    "        print('Trainable number of parameters: {:,}'.format(trainable_count))\n",
    "        print('Non-trainable number of parameters: {:,}'.format(non_trainable_count))\n",
    "        \n",
    "\n",
    "        # model dataset init\n",
    "        df_triplest = self.get_triplets(self.df_full)\n",
    "        print('Training data length: {:,}'.format(df_triplest.shape[0]))\n",
    "        X = {\n",
    "            'user_input': tf.convert_to_tensor(df_triplest.user_id, dtype=tf.int32),\n",
    "            'positive_item_input': tf.convert_to_tensor(df_triplest.positive_m_id, dtype=tf.int32),\n",
    "            'negative_item_input': tf.convert_to_tensor(df_triplest.negative_m_id, dtype=tf.int32)\n",
    "        }\n",
    "\n",
    "        # model training\n",
    "        model.fit(X, \n",
    "                tf.ones(df_triplest.shape[0]), \n",
    "                batch_size=batch_size,\n",
    "                epochs=num_epochs)\n",
    "\n",
    "        self.model = model \n",
    "\n",
    "    def inference(self, user, items):\n",
    "        user_id = 0\n",
    "        try:\n",
    "            user_id = self.user2id_map[user]\n",
    "        except:\n",
    "            print(f\"User; {user}, does not exists in the training dataset\")\n",
    "        \n",
    "        item_ids = []\n",
    "        for i in items:\n",
    "            try:\n",
    "                item_ids.append(self.item2id_map[i])\n",
    "            except:\n",
    "                print(f\"Item {i}, does not exists in the training dataset\")\n",
    "\n",
    "        if (user_id==0) or (item_ids==[]):\n",
    "            print(\"Not enough data for the inference\")\n",
    "            return\n",
    "        else:\n",
    "            result_df = self.ranking(self.model, user_id, item_ids)\n",
    "            result_df['item'] = result_df['item_id'].map(self.id2item_map)\n",
    "            return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = BPRModel(df_full, 'user', 'movie', 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 918,750.0\n",
      "Trainable number of parameters: 918,750\n",
      "Non-trainable number of parameters: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:02<00:00, 426.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 1,109,044\n",
      "Epoch 1/3\n",
      "4333/4333 [==============================] - 26s 6ms/step - loss: 0.0385\n",
      "Epoch 2/3\n",
      "4333/4333 [==============================] - 26s 6ms/step - loss: 8.3528e-05\n",
      "Epoch 3/3\n",
      "4333/4333 [==============================] - 26s 6ms/step - loss: 7.8493e-06\n"
     ]
    }
   ],
   "source": [
    "bpr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1.937564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>861</td>\n",
       "      <td>1.481060</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1009</td>\n",
       "      <td>-1.258224</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510</td>\n",
       "      <td>-2.343066</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>-3.429435</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>-4.794955</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id     score  item\n",
       "2       24  1.937564     1\n",
       "0      861  1.481060   123\n",
       "5     1009 -1.258224    76\n",
       "1      510 -2.343066   122\n",
       "3      615 -3.429435    43\n",
       "4       79 -4.794955    54"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.inference(12, [123, 122, 1, 43, 54, 76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "114915f1d81c1da50642110d3f97d7e46f1e3067055e32d41ec3bf538df62b4a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('rec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
