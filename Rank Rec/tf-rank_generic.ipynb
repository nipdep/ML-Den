{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow-ranking\n",
    "! pip install --upgrade tensorflow-datasets\n",
    "! pip install --upgrade pip setuptools\n",
    "! pip install recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds \n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from recommenders.datasets import movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:11<00:00, 436KB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>875747190</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5.0</td>\n",
       "      <td>883888671</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>879138235</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5.0</td>\n",
       "      <td>876503793</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId  Rating  Timestamp         Title\n",
       "0     196      242     3.0  881250949  Kolya (1996)\n",
       "1      63      242     3.0  875747190  Kolya (1996)\n",
       "2     226      242     5.0  883888671  Kolya (1996)\n",
       "3     154      242     3.0  879138235  Kolya (1996)\n",
       "4     306      242     5.0  876503793  Kolya (1996)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size='100k',\n",
    "    header=['UserId', 'MovieId', 'Rating', 'Timestamp'],\n",
    "    title_col='Title'\n",
    ")\n",
    "\n",
    "data.loc[:, 'Rating'] = data['Rating'].astype(np.float32)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensRankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, user_vocab, movie_vocab):\n",
    "        super().__init__()\n",
    "        self.user_vocab = user_vocab\n",
    "        self.movie_vocab = movie_vocab\n",
    "        self.user_embed = tf.keras.layers.Embedding(user_vocab.vocabulary_size(), 64)\n",
    "        self.movie_embed = tf.keras.layers.Embedding(movie_vocab.vocabulary_size(), 64)\n",
    "\n",
    "    def call(self, feature):\n",
    "        user_embedding = self.user_embed(self.user_vocab(feature['user_id']))\n",
    "        movie_embedding = self.movie_embed(self.movie_vocab(feature['movie_title']))\n",
    "        return tf.reduce_sum(user_embedding*movie_embedding, axis=2)\n",
    "\n",
    "\n",
    "class TFRankModel(object):\n",
    "\n",
    "    def __init__(self, df, user_col, item_col, rating_col):\n",
    "        self.data = df \n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.rating_col = rating_col\n",
    "        self.__prep_dataset()\n",
    "\n",
    "\n",
    "    def __prep_dataset(self):\n",
    "        \"\"\"build tf Dataset object from pd.DataFrame and movie_id, user_id tf.Tensors\n",
    "        \"\"\"\n",
    "        title_tf = tf.convert_to_tensor(self.data[self.item_col].astype(str).values, dtype=tf.string)\n",
    "        user_tf = tf.convert_to_tensor(self.data[self.user_col].astype(str).values, dtype=tf.string)\n",
    "        rating_tf = tf.convert_to_tensor(self.data[self.rating_col].values, dtype=tf.float16)\n",
    "        self.rating = tf.data.Dataset.from_tensor_slices({'movie_title': title_tf, 'user_id': user_tf, 'user_rating': rating_tf})\n",
    "        self.movies = tf.convert_to_tensor(self.data[self.item_col].astype(str).unique(), dtype=tf.string)\n",
    "        self.users = tf.convert_to_tensor(self.data[self.user_col].astype(str).unique(), dtype=tf.string)\n",
    "\n",
    "    def build_embedding(self, bs=32):\n",
    "        \"\"\"create embedding lookups & batched datasets\n",
    "\n",
    "        Args:\n",
    "            bs (int, optional): batch size of the ragged dataset. Defaults to 32.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: batch dataset object for tf model training\n",
    "        \"\"\"\n",
    "        self.user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "        self.user_ids_vocabulary.adapt(self.users)\n",
    "\n",
    "        self.movie_title_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "        self.movie_title_vocabulary.adapt(self.movies)\n",
    "\n",
    "        key_func = lambda x: self.user_ids_vocabulary(x['user_id'])\n",
    "        reduce_func = lambda key, dataset: dataset.batch(100)\n",
    "        ds_train = self.rating.group_by_window(key_func=key_func, reduce_func=reduce_func, window_size=100)\n",
    "\n",
    "        def _feature_and_labels(x):\n",
    "            labels = x.pop(\"user_rating\")\n",
    "            return x, labels \n",
    "\n",
    "        ds_train = ds_train.map(_feature_and_labels)\n",
    "        ds_train = ds_train.apply(tf.data.experimental.dense_to_ragged_batch(batch_size=bs))\n",
    "        return ds_train\n",
    "\n",
    "    def train(self, lr=0.01, num_epochs=3, bs=32, save_dir=''):\n",
    "        \"\"\"build & train the model\n",
    "\n",
    "        Args:\n",
    "            lr (float, optional): learning rate. Defaults to 0.01.\n",
    "            num_epochs (int, optional): number of epochs. Defaults to 3.\n",
    "            bs (int, optional): batch size of the dataset. Defaults to 32.\n",
    "\n",
    "        Returns:\n",
    "            status : 1 > success , 0 > failed, \n",
    "            message : the status message\n",
    "        \"\"\"\n",
    "        result_cfg = {'status': 1, 'message': 'Model Trained Successfully'}\n",
    "        try:\n",
    "            ds_train = self.build_embedding(bs)\n",
    "            self.model = MovieLensRankingModel(self.user_ids_vocabulary, self.movie_title_vocabulary)\n",
    "            optimizer = tf.keras.optimizers.Adagrad(lr)\n",
    "            loss = tfr.keras.losses.get(loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
    "            eval_metrics = [\n",
    "                tfr.keras.metrics.get(key='ndcg', name='metric/ndcg', ragged=True),\n",
    "                tfr.keras.metrics.get(key='mrr', name='metric/mrr', ragged=True)\n",
    "            ]\n",
    "            self.model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "\n",
    "            self.model.fit(ds_train, epochs=num_epochs)\n",
    "            self.model.save_weights(save_dir)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            result_cfg = {'status': 0, 'message': 'There was an error in the model training process. Try Again..'}\n",
    "        return None, result_cfg\n",
    "\n",
    "    def inference(self, user, items, save_dir):\n",
    "        \"\"\"inference / rank the items for the given user\n",
    "\n",
    "        Args:\n",
    "            user (int/ str): user_id according to training dataset\n",
    "            items (List[int], List[str]): list of item_id according to training dataset\n",
    "\n",
    "        Returns:\n",
    "            res_df (pd.DataFrame) : sorted list of items\n",
    "            status : 2 > Warning , 1 > success , 0 > failed\n",
    "            message : status info message\n",
    "        \"\"\"\n",
    "        all_users = list(self.data[self.user_col].unique())\n",
    "        all_items = list(self.data[self.item_col].unique())\n",
    "        ds_train = self.build_embedding(32)\n",
    "        model = MovieLensRankingModel(self.user_ids_vocabulary, self.movie_title_vocabulary)\n",
    "        model.load_weights(save_dir)\n",
    "        result_cfg = {'status': 1, 'message': ''}\n",
    "        if user in all_users:\n",
    "            non_existing_items = [i for i in items if i not in all_items]\n",
    "            if len(non_existing_items) != len(items):\n",
    "                if non_existing_items != []:\n",
    "                    result_cfg = {'status': 2, 'message': ' '.join(non_existing_items)+' does not exists in the training dataset!'}\n",
    "                try:\n",
    "                    inputs = {\n",
    "                        'user_id': tf.expand_dims(tf.repeat(str(user), repeats=self.movies.shape[0]), axis=0),\n",
    "                        'movie_title': tf.expand_dims(self.movies, axis=0)\n",
    "                    }\n",
    "                    # model = tf.keras.models.load_model(save_dir)\n",
    "                    scores = model(inputs)\n",
    "                    titles = tfr.utils.sort_by_scores(scores, [tf.expand_dims(self.movies, axis=0)])[0]\n",
    "\n",
    "                    res_df = pd.DataFrame({'user': user, 'score': tf.sort(scores).numpy()[0],'item': titles.numpy()[0]})\n",
    "                    res_df['item'] = res_df['item'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "                    output_df = res_df.loc[res_df['item'].isin(items)].sort_values('score', ascending=False)\n",
    "                    return output_df, result_cfg\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    result_cfg = {'status': 0, 'message': 'There was an error in the inference process. Try Again..'}\n",
    "                    return None, result_cfg\n",
    "            else:\n",
    "                return None, {'status': 0, 'message': 'None of the items given exists in the training dataset!'}\n",
    "        else:\n",
    "            return None, {'status': 0, 'message': f'The user;{user} does not exists in the training dataset!'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'df': data,\n",
    "    'user_col': 'UserId',\n",
    "    'item_col': 'Title',\n",
    "    'rating_col': 'Rating',\n",
    "    'bs': 32,\n",
    "    'lr': 0.001,\n",
    "    'n': 3,\n",
    "    'save_dir': '/tmp/models/exp-001'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model = TFRankModel(model_cfg['df'], model_cfg['user_col'], model_cfg['item_col'], model_cfg['rating_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nipunpathitage/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/RaggedToTensor_2/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/RaggedToTensor_2/boolean_mask/GatherV2:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/RaggedToTensor_2/Shape:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/nipunpathitage/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_lens_ranking_model_18/RaggedTile/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_lens_ranking_model_18/RaggedTile/Reshape_2:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_lens_ranking_model_18/RaggedTile/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/nipunpathitage/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_lens_ranking_model_18/RaggedTile_1/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_lens_ranking_model_18/RaggedTile_1/Reshape_2:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_lens_ranking_model_18/RaggedTile_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 4s 36ms/step - loss: 1000.3473 - metric/ndcg: 0.8095 - metric/mrr: 1.0000\n",
      "Epoch 2/3\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 1000.3465 - metric/ndcg: 0.8097 - metric/mrr: 1.0000\n",
      "Epoch 3/3\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 1000.3458 - metric/ndcg: 0.8100 - metric/mrr: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, {'status': 1, 'message': 'Model Trained Successfully'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'tmp/models/exp-001'\n",
    "rank_model.train(model_cfg['lr'], num_epochs=model_cfg['n'], bs=model_cfg['bs'], save_dir=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'accumulator' for (root).user_embed.embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'accumulator' for (root).user_embed.embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'accumulator' for (root).movie_embed.embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'accumulator' for (root).movie_embed.embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      user     score                      item\n",
       " 1603    12  0.011548          Toy Story (1995)\n",
       " 855     12  0.000285             Brazil (1985)\n",
       " 263     12 -0.006612  Conspiracy Theory (1997)\n",
       " 132     12 -0.009007      Jerry Maguire (1996),\n",
       " {'status': 1, 'message': ''})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = rank_model.inference(12, ['Toy Story (1995)', 'Brazil (1985)', 'Jerry Maguire (1996)', 'Conspiracy Theory (1997)'], save_path)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "sdict = {1: 4}\n",
    "ddict = defaultdict(lambda : None, sdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ddict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4342e088104506c762c0bda77e093724389a62f7580ab4d8d79c756006761a67"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('wave_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
