{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from recommenders.datasets import movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:07<00:00, 625KB/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>196_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>63_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>226_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>154_242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>306_242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating       id\n",
       "0   196    242       3  196_242\n",
       "1    63    242       3   63_242\n",
       "2   226    242       5  226_242\n",
       "3   154    242       3  154_242\n",
       "4   306    242       5  306_242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size='100k',\n",
    "    header=['user', 'movie', 'rating', 'Timestamp'],\n",
    "    title_col='title'\n",
    ")\n",
    "\n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.int32)\n",
    "data['id'] = data.apply(lambda x: str(x['user'])+\"_\"+str(x['movie']), axis=1)\n",
    "df_full = data.loc[:, ['user', 'movie', 'rating', 'id']]\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>sex</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "      <td>f</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the black dahlia murder</td>\n",
       "      <td>f</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>goldfrapp</td>\n",
       "      <td>f</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dropkick murphys</td>\n",
       "      <td>f</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>le tigre</td>\n",
       "      <td>f</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                   artist sex  country\n",
       "0     1    red hot chili peppers   f  Germany\n",
       "1     1  the black dahlia murder   f  Germany\n",
       "2     1                goldfrapp   f  Germany\n",
       "3     1         dropkick murphys   f  Germany\n",
       "4     1                 le tigre   f  Germany"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('../data/lastfm.csv')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = pd.read_csv('../data/movielens.csv')\n",
    "data0.head()\n",
    "data = data0.loc[:, ['UserId', 'MovieId', 'Rating']]\n",
    "data.rename(columns={'UserId': 'user', 'MovieId': 'movie', 'Rating': 'rating'}, inplace=True)\n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.int32)\n",
    "data['id'] = data.apply(lambda x: str(x['user'])+\"_\"+str(x['movie']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRModel(object):\n",
    "\n",
    "    def __init__(self, df, user_col, item_col, rating_col=None, explicit=True, save_dir='../tmp/models/exp-002'):\n",
    "        self.explicit = explicit\n",
    "        self.df_full = df\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.rating_col = rating_col\n",
    "        self.save_dir = save_dir\n",
    "        self.build_mappings(self.user_col, self.item_col)\n",
    "        self.add_id_cols()\n",
    "\n",
    "    def build_mappings(self, user_col, item_col):\n",
    "        unique_users = self.df_full[user_col].unique()\n",
    "        self.user2id_map = dict(zip(unique_users, np.arange(unique_users.shape[0], dtype=np.int32)))\n",
    "        self.id2user_map = dict(zip(np.arange(unique_users.shape[0], dtype=np.int32), unique_users))\n",
    "\n",
    "        unique_movies = self.df_full[item_col].unique()\n",
    "        self.item2id_map = dict(zip(unique_movies, np.arange(unique_movies.shape[0], dtype=np.int32)))\n",
    "        self.id2item_map = dict(zip(np.arange(unique_movies.shape[0], dtype=np.int32), unique_movies))\n",
    "\n",
    "    def add_id_cols(self):\n",
    "        self.df_full['user_id'] = self.df_full[self.user_col].apply(lambda u: self.user2id_map[u])\n",
    "        self.df_full['movie_id'] = self.df_full[self.item_col].apply(lambda m: self.item2id_map[m])\n",
    "\n",
    "    def get_triplets_exp(self, df_train, cfg):\n",
    "\n",
    "        try:\n",
    "            threshold = cfg['threshold']\n",
    "        except:\n",
    "            threshold = 3\n",
    "        \n",
    "        try:\n",
    "            take_nonexisting = cfg['take_nonexisiting']\n",
    "        except:\n",
    "            take_nonexisting = False \n",
    "        \n",
    "        try:\n",
    "            item_limit = cfg['item_limit']\n",
    "        except:\n",
    "            item_limit = 50\n",
    "\n",
    "        df_triplest = pd.DataFrame(columns=['user_id', 'positive_m_id', 'negative_m_id'])\n",
    "        data = []\n",
    "        users_without_data = []\n",
    "\n",
    "        for user_id in tqdm(df_train.user_id.unique()):\n",
    "            positive_movies = df_train[(df_train.user_id == user_id) & (df_train[self.rating_col] > threshold)].movie_id.values\n",
    "            negative_movies = df_train[(df_train.user_id == user_id) & (df_train[self.rating_col] <= threshold)].movie_id.values\n",
    "            if take_nonexisting:\n",
    "                all_movies = df_train.movie_id.unique()\n",
    "                nonext_movies = np.setdiff1d(all_movies, df_train.loc[df_train[self.user_col]==user_id].movie_id.values)\n",
    "                negative_movies = np.concatenate((negative_movies, nonext_movies), axis=0)\n",
    "\n",
    "            if negative_movies.shape[0] == 0 or positive_movies.shape[0] == 0:\n",
    "                users_without_data.append(user_id)\n",
    "                continue\n",
    "            \n",
    "            np.random.shuffle(positive_movies)\n",
    "            positive_movies = positive_movies[:item_limit]\n",
    "\n",
    "            np.random.shuffle(negative_movies)\n",
    "            negative_movies = negative_movies[:item_limit]\n",
    "\n",
    "            for positive_movie in positive_movies:\n",
    "                for negative_movie in negative_movies:\n",
    "                    data.append({'user_id': user_id, 'positive_m_id': positive_movie, 'negative_m_id': negative_movie})\n",
    "\n",
    "        df_triplest = df_triplest.append(data, ignore_index=True)\n",
    "        return df_triplest\n",
    "\n",
    "    def get_triplets_imp(self, df_train, cfg):\n",
    "\n",
    "        try:\n",
    "            item_limit = cfg['item_limit']\n",
    "        except:\n",
    "            item_limit = 50\n",
    "\n",
    "        df_triplest = pd.DataFrame(columns=['user_id', 'positive_m_id', 'negative_m_id'])\n",
    "        data = []\n",
    "        users_without_data = []\n",
    "\n",
    "        for user_id in tqdm(df_train.user_id.unique()):\n",
    "            all_movies = df_train.movie_id.unique()\n",
    "            positive_movies = df_train.loc[df_train[self.user_col]==user_id].movie_id.values\n",
    "            negative_movies = np.setdiff1d(all_movies, positive_movies)\n",
    "\n",
    "            if negative_movies.shape[0] == 0 or positive_movies.shape[0] == 0:\n",
    "                users_without_data.append(user_id)\n",
    "                continue\n",
    "\n",
    "            np.random.shuffle(positive_movies)\n",
    "            positive_movies = positive_movies[:item_limit]\n",
    "\n",
    "            np.random.shuffle(negative_movies)\n",
    "            negative_movies = negative_movies[:item_limit]\n",
    "\n",
    "            for positive_movie in positive_movies:\n",
    "                for negative_movie in negative_movies:\n",
    "                    data.append({'user_id': user_id, 'positive_m_id': positive_movie, 'negative_m_id': negative_movie})\n",
    "\n",
    "        df_triplest = df_triplest.append(data, ignore_index=True)\n",
    "        return df_triplest\n",
    "\n",
    "    def bpr_predict(self, model: Model, user_id: int, item_ids: list, user_layer='user_embedding', item_layer='item_embedding'):\n",
    "        \"\"\"\n",
    "        Predict by multiplication user vector by item matrix\n",
    "        \n",
    "        :return: list of the scores\n",
    "        \"\"\"\n",
    "        user_vector = model.get_layer(user_layer).get_weights()[0][user_id]\n",
    "        item_matrix = model.get_layer(item_layer).get_weights()[0][item_ids]\n",
    "\n",
    "        scores = (np.dot(user_vector, item_matrix.T))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def ranking(self, model, user_id, item_ids):\n",
    "        item_scores = [self.bpr_predict(model, user_id, i) for i in item_ids]\n",
    "        res_df = pd.DataFrame({'item_id': item_ids, 'score': item_scores}).sort_values(by='score', ascending=False)\n",
    "        return res_df\n",
    "\n",
    "    @tf.function\n",
    "    def identity_loss(self, _, y_pred):\n",
    "        return tf.math.reduce_mean(y_pred)\n",
    "\n",
    "    @tf.function\n",
    "    def bpr_triplet_loss(self, X: dict):\n",
    "        \"\"\"\n",
    "        Calculate triplet loss - as higher the difference between positive interactions\n",
    "        and negative interactions as better\n",
    "\n",
    "        :param X: X contains the user input, positive item input, negative item input\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "        positive_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, positive_item_latent), axis=-1, keepdims=True)\n",
    "        negative_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, negative_item_latent), axis=-1, keepdims=True)\n",
    "\n",
    "        return tf.math.subtract(tf.constant(1.0), tf.sigmoid(tf.math.subtract(positive_interactions, negative_interactions)))\n",
    "\n",
    "    def out_shape(self, shapes):\n",
    "        return shapes[0]\n",
    "        \n",
    "\n",
    "    def build_model(self, num_users: int, num_items: int, latent_dim: int) -> Model:\n",
    "        \"\"\"\n",
    "        Build a model for Bayesian personalized ranking\n",
    "\n",
    "        :param num_users: a number of the unique users\n",
    "        :param num_items: a number of the unique movies\n",
    "        :param latent_dim: vector length for the latent representation\n",
    "        :return: Model\n",
    "        \"\"\"\n",
    "        user_input = Input((1,), name='user_input')\n",
    "\n",
    "        positive_item_input = Input((1,), name='positive_item_input')\n",
    "        negative_item_input = Input((1,), name='negative_item_input')\n",
    "        # One embedding layer is shared between positive and negative items\n",
    "        item_embedding_layer = Embedding(num_items, latent_dim, name='item_embedding', input_length=1)\n",
    "\n",
    "        positive_item_embedding = Flatten()(item_embedding_layer(positive_item_input))\n",
    "        negative_item_embedding = Flatten()(item_embedding_layer(negative_item_input))\n",
    "\n",
    "        user_embedding = Embedding(num_users, latent_dim, name='user_embedding', input_length=1)(user_input)\n",
    "        user_embedding = Flatten()(user_embedding)\n",
    "\n",
    "        triplet_loss = Lambda(self.bpr_triplet_loss, output_shape=self.out_shape)([positive_item_embedding,\n",
    "                                                                negative_item_embedding,\n",
    "                                                                user_embedding])\n",
    "\n",
    "        model = Model(inputs=[positive_item_input, negative_item_input, user_input], outputs=triplet_loss)\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def train(self, save_dir, latent_dim=350, batch_size=256, num_epochs=3, lr=0.002, dataset_cfg={}):\n",
    "        \"\"\"model building & training\n",
    "\n",
    "        Args:\n",
    "            latent_dim (int, optional): embedding vector length for each lookup. Defaults to 350.\n",
    "            batch_size (int, optional): batch size. Defaults to 256.\n",
    "            num_epochs (int, optional): number of epochs. Defaults to 3.\n",
    "            lr (float, optional): learning rate. Defaults to 0.002.\n",
    "            dataset_cfg (dict, optional): triplate dataset building function parameters. Defaults to {}.\n",
    "\n",
    "        Returns:\n",
    "            status : 1 > success , 0 > failed, \n",
    "            message : the status message\n",
    "        \"\"\"\n",
    "        result_cfg = {'status': 1, 'message': 'Model Trained Successfully'}\n",
    "        # try:\n",
    "        num_users = len(self.user2id_map)\n",
    "        num_items = len(self.item2id_map)\n",
    "        model = self.build_model(num_users, num_items, latent_dim)\n",
    "        model.compile(loss=self.identity_loss, optimizer=Adam(learning_rate=lr))\n",
    "\n",
    "        # parameter space logging\n",
    "        trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "        non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "        print('Total number of parameters: {:,}'.format(trainable_count + non_trainable_count))\n",
    "        print('Trainable number of parameters: {:,}'.format(trainable_count))\n",
    "        print('Non-trainable number of parameters: {:,}'.format(non_trainable_count))\n",
    "        \n",
    "\n",
    "        # model dataset init\n",
    "        if self.explicit:\n",
    "            df_triplest = self.get_triplets_exp(self.df_full, dataset_cfg)\n",
    "        else:\n",
    "            df_triplest = self.get_triplets_imp(self.df_full, dataset_cfg)\n",
    "        print('Training data length: {:,}'.format(df_triplest.shape[0]))\n",
    "        X = {\n",
    "            'user_input': tf.convert_to_tensor(df_triplest.user_id, dtype=tf.int32),\n",
    "            'positive_item_input': tf.convert_to_tensor(df_triplest.positive_m_id, dtype=tf.int32),\n",
    "            'negative_item_input': tf.convert_to_tensor(df_triplest.negative_m_id, dtype=tf.int32)\n",
    "        }\n",
    "\n",
    "        # model training\n",
    "        model.fit(X, \n",
    "                tf.ones(df_triplest.shape[0]), \n",
    "                batch_size=batch_size,\n",
    "                epochs=num_epochs)\n",
    "        model.save_weights(save_dir)\n",
    "        self.model = model \n",
    "        # except:\n",
    "        #     result_cfg = {'status': 0, 'message': 'There was an error in the model training process. Try Again..'}\n",
    "        return None, result_cfg\n",
    "\n",
    "    def inference(self, user, items, save_dir):\n",
    "        \"\"\"inference / rank the items for the given user\n",
    "\n",
    "        Args:\n",
    "            user (int/ str): user_id according to training dataset\n",
    "            items (List[int], List[str]): list of item_id according to training dataset\n",
    "\n",
    "        Returns:\n",
    "            res_df (pd.DataFrame) : sorted list of items\n",
    "            status : 2 > Warning , 1 > success , 0 > failed\n",
    "            message : status info message\n",
    "        \"\"\"\n",
    "        result_cfg = {'status': 1, 'message': ''}\n",
    "        num_users = len(self.user2id_map)\n",
    "        num_items = len(self.item2id_map)\n",
    "        model = self.build_model(num_users, num_items, 350)\n",
    "        model.load_weights(save_dir)\n",
    "        user_id = 0\n",
    "        try:\n",
    "            user_id = self.user2id_map[user]\n",
    "        except:\n",
    "            result_cfg = {'status': 0, 'message': f\"User; {user}, does not exists in the training dataset\"}\n",
    "            return None, result_cfg\n",
    "        \n",
    "        item_ids = []\n",
    "        for i in items:\n",
    "            try:\n",
    "                item_ids.append(self.item2id_map[i])\n",
    "            except:\n",
    "                result_cfg['status'] = 2, \n",
    "                if result_cfg['message'] == '':\n",
    "                    result_cfg['message'] =  f' {i} does not exists in the training dataset!'\n",
    "                else:\n",
    "                    result_cfg['message'] = f' {i} ' + result_cfg['message']\n",
    "\n",
    "        if item_ids==[]:\n",
    "            result_cfg = {'status': 0, 'message': 'None of the items given exists in the training dataset!'}\n",
    "            return None, result_cfg\n",
    "        else:\n",
    "            result_df = self.ranking(model, user_id, item_ids)\n",
    "            result_df['item'] = result_df['item_id'].map(self.id2item_map)\n",
    "            result_df['user'] = user \n",
    "            result_df = result_df.loc[:, ['user', 'score', 'item']]\n",
    "            return result_df, result_cfg\n",
    "\n",
    "    def batch_pred(self, df):\n",
    "        result_cfg = {'status': 1, 'message': ''}\n",
    "        user_Kdf = df.groupby('user')['item'].apply(list).reset_index()\n",
    "        res_dfs = []\n",
    "        for _, row in user_Kdf.iterrows():\n",
    "            rdf, sms = bpr.inference(int(row['user']), row['item'])\n",
    "            if sms['status'] == 1:\n",
    "                res_dfs.append(rdf)\n",
    "            else:\n",
    "                result_cfg['status'] = 2\n",
    "                result_cfg['message'] += sms['message']\n",
    "        res_df = pd.concat(res_dfs, axis=0)\n",
    "        return res_df, result_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'df': data,\n",
    "    'user_col': 'user',\n",
    "    'item_col': 'movie',\n",
    "    'rating_col': 'rating',\n",
    "    'explicit': True,\n",
    "    'threshold': 2,\n",
    "    'take_nonexisting': True,\n",
    "    'item_limit': 50,\n",
    "    'latent_dim': 350,\n",
    "    'bs': 256,\n",
    "    'n': 3,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'tmp/models/exp-002'\n",
    "bpr = BPRModel(model_cfg['df'], model_cfg['user_col'], model_cfg['item_col'], model_cfg['rating_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 09:50:38.425968: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 918,750.0\n",
      "Trainable number of parameters: 918,750\n",
      "Non-trainable number of parameters: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:01<00:00, 506.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 1,109,044\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 09:50:41.802958: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4333/4333 [==============================] - 24s 5ms/step - loss: 0.0385\n",
      "Epoch 2/3\n",
      "4333/4333 [==============================] - 25s 6ms/step - loss: 8.3146e-05\n",
      "Epoch 3/3\n",
      "4333/4333 [==============================] - 25s 6ms/step - loss: 7.8233e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, {'status': 1, 'message': 'Model Trained Successfully'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.train(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.embeddings\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   user     score  item\n",
       " 2    12  3.028188     1\n",
       " 4    12  0.780196    54\n",
       " 5    12  0.297961    76\n",
       " 0    12 -1.533885   123\n",
       " 1    12 -2.067558   122\n",
       " 3    12 -2.133079    43,\n",
       " {'status': 1, 'message': ''})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.inference(12, [123, 122, 1, 43, 54, 76], save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item\n",
       "0    12   123\n",
       "1    12   352\n",
       "2    12    45\n",
       "3    12    65\n",
       "4    34   123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dfs = pd.DataFrame({'user': [12, 12, 12, 12, 34, 34, 34, 56, 56, 56, 56, 56], 'item': [123, 352, 45, 65, 123, 43, 34, 23, 43, 12, 14, 233]})\n",
    "sample_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[123, 352, 45, 65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>[123, 43, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>[23, 43, 12, 14, 233]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                   item\n",
       "0    12     [123, 352, 45, 65]\n",
       "1    34          [123, 43, 34]\n",
       "2    56  [23, 43, 12, 14, 233]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df = sample_dfs.groupby('user')['item'].apply(list).reset_index()\n",
    "list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dfs = []\n",
    "for index, row in list_df.iterrows():\n",
    "    # print(type(row['item']))\n",
    "    rdf, sms = bpr.inference(int(row['user']), row['item'])\n",
    "    if sms['status'] == 1:\n",
    "        res_dfs.append(rdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>score</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.069623</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>-1.143507</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>-1.533491</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>-2.775054</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.462985</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user     score  item\n",
       "2    12 -0.069623    45\n",
       "1    12 -1.143507   352\n",
       "0    12 -1.533491   123\n",
       "3    12 -2.775054    65\n",
       "1    34 -0.462985    43"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.concat(res_dfs, axis=0)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'df': data1,\n",
    "    'user_col': 'user',\n",
    "    'item_col': 'artist',\n",
    "    'rating_col': None,\n",
    "    'explicit': True,\n",
    "    'threshold': 2,\n",
    "    'take_nonexisting': True,\n",
    "    'item_limit': 50,\n",
    "    'latent_dim': 350,\n",
    "    'bs': 256,\n",
    "    'n': 3,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = BPRModel(model_cfg['df'], model_cfg['user_col'], model_cfg['item_col'], model_cfg['rating_col'], explicit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 13:09:04.038527: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 5,601,400.0\n",
      "Trainable number of parameters: 5,601,400\n",
      "Non-trainable number of parameters: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:34<00:00, 438.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 11,039,400\n",
      "Epoch 1/3\n",
      "43123/43123 [==============================] - 1778s 41ms/step - loss: 0.0130\n",
      "Epoch 2/3\n",
      "43123/43123 [==============================] - 1828s 42ms/step - loss: 3.2317e-07\n",
      "Epoch 3/3\n",
      "43123/43123 [==============================] - 1914s 44ms/step - loss: 1.5389e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, {'status': 1, 'message': 'Model Trained Successfully'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({'user': [12, 12, 34, 34, 34, 34, 32, 32, 32],\n",
    "                          'item': ['edguy', 'jack johnson', 'the killers', 'judas priest', 'the who', 'le tigre', 'le tigre', 'aphex twin', 'edguy']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>edguy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>jack johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>the killers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>judas priest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>the who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>le tigre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>le tigre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>aphex twin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>edguy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user          item\n",
       "0    12         edguy\n",
       "1    12  jack johnson\n",
       "2    34   the killers\n",
       "3    34  judas priest\n",
       "4    34       the who\n",
       "5    34      le tigre\n",
       "6    32      le tigre\n",
       "7    32    aphex twin\n",
       "8    32         edguy"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('../data/test_lastfm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({'user': [12, 12, 12, 12, 43 ,43, 43, 43, 43, 43, 53, 53, 53, 53, 53, 53, 53, 112, 112, 112],\n",
    "                         'item': [12, 23, 112, 43, 58, 97, 38, 233, 675, 73, 94, 67, 232, 226, 113, 756, 234, 12, 31, 43]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>112</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>112</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user  item\n",
       "0     12    12\n",
       "1     12    23\n",
       "2     12   112\n",
       "3     12    43\n",
       "4     43    58\n",
       "5     43    97\n",
       "6     43    38\n",
       "7     43   233\n",
       "8     43   675\n",
       "9     43    73\n",
       "10    53    94\n",
       "11    53    67\n",
       "12    53   232\n",
       "13    53   226\n",
       "14    53   113\n",
       "15    53   756\n",
       "16    53   234\n",
       "17   112    12\n",
       "18   112    31\n",
       "19   112    43"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('../data/test_movielens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4342e088104506c762c0bda77e093724389a62f7580ab4d8d79c756006761a67"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('wave_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
